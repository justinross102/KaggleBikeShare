preg_wf <- workflow() %>%
add_recipe(pen_reg_recipe) %>%
add_model(preg_model)
# Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = L)
# split data for CV
folds <- vfold_cv(log_bikes, v = K, repeats = 1)
# Penalized regression model
preg_model <- linear_reg(penalty=tune(), mixture=tune()) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
preg_wf <- workflow() %>%
add_recipe(pen_reg_recipe) %>%
add_model(preg_model)
# Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = L)
# Grid of values to tune over
penalty_values <- 10^seq(-2, 2, by = 0.5)
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = penalty_values)
# Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 3)
# Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = c(3,3))
# split data for CV
folds <- vfold_cv(log_bikes, v = K, repeats = 1)
# split data for CV
folds <- vfold_cv(log_bikes, v = 10, repeats = 1)
# run the CV
CV_results <- preg_wf %>%
tune_grid(resamples=folds,
grid = tuning_grid,
metrics = metric_set(rmse, mae, rsq))
# split data for CV
folds <- vfold_cv(log_bikes, v = 5, repeats = 1)
# run the CV
CV_results <- preg_wf %>%
tune_grid(resamples=folds,
grid = tuning_grid,
metrics = metric_set(rmse, mae, rsq))
# find best tuning parameters
best_tune <- CV_results %>%
select_best("rmse")
best_tune
# Libraries
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(poissonreg)
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
## Transform to log(count) - I can only do this on train set because
## test set does not have count. Hence, I am doing this outside of recipe
## because I only apply this to the train set
log_bikes <- bikes %>%
mutate(count=log(count))
## Create a recipe
pen_reg_recipe <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_pen_reg_recipe <- prep(pen_reg_recipe)
## Penalized regression model
preg_model <- linear_reg(penalty=0.0000000001, mixture=1) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
preg_wf <- workflow() %>%
add_recipe(pen_reg_recipe) %>%
add_model(preg_model) %>%
fit(data=log_bikes)
# Get Predictions for the test set AND format for Kaggle
log_lin_preds <- predict(preg_wf, new_data=test_data) %>% # This predicts log(count)
bind_cols(test_data, .) %>% # Bind test data with predictions
select(datetime, .pred) %>% # Select datetime and predictions
rename(count=.pred) %>% # Rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) # Needed for the right format for Kaggle
# Write predictions to CSV
vroom_write(x=log_lin_preds, file="./LogLinearPreds.csv", delim=",")
# finalize workflow and fit it
final_wf <- preg_wf %>%
finalize_workflow(best_tune) %>%
fit(data=log_bikes)
# predict
test <- predict(final_wf, new_data=test_data) %>% # This predicts log(count)
bind_cols(test_data, .) %>% # Bind test data with predictions
select(datetime, .pred) %>% # Select datetime and predictions
rename(count=.pred) %>% # Rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) # Needed for the right format for Kaggle
# Write predictions to CSV
vroom_write(x=test, file="./test.csv", delim=",")
# Read in the Data
bike_tr <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
logbike_tr <- bike_tr %>% mutate(count = log(count))
# Read in the Data
bike_tr <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bike_tr <- bike_tr %>%
select(-casual, - registered)
logbike_tr <- bike_tr %>% mutate(count = log(count))
#penalized code
#recipe for putting together the first count or filtering
my_recipe <- recipe(count ~ datetime + season + holiday + workingday
+ weather + temp + humidity,
data=logbike_tr) %>% # Set model formula
step_mutate(weather_cat = as_factor(weather)) %>% #changes weather from numeric to factor
step_poly(temp, degree=2) %>% #Create polynomial expansion of temperature
step_time(datetime, features=c("hour", "minute")) %>% #break out datetime
step_dummy(all_nominal_predictors()) %>% #create dummy variables (for weather)
step_zv(all_predictors()) %>% #removes zero-variance predictors
step_rm(weather, datetime) %>% #removes weather since it is now categorized
step_normalize(all_numeric_predictors())
bike_te <- vroom("./test.csv")
prepped_recipe <- prep(my_recipe) # Sets up the preprocessing using recipie
bake(prepped_recipe, new_data = bike_te)
bake(prepped_recipe, new_data = bike_te)
# Remove casual and registered because we can't use them to predict
bike_tr <- bike_tr %>%
select(-casual, - registered)
# Libraries
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(poissonreg)
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
## Create a recipe
pen_reg_recipe <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_pen_reg_recipe <- prep(pen_reg_recipe)
bake(prepped_pen_reg_recipe, new_data = test_data) # Make sure recipe works on test
bake(prepped_pen_reg_recipe, new_data = log_bikes) # Make sure recipe works on test
bake(prepped_pen_reg_recipe, new_data = test_data) # Make sure recipe works on train
test_data
test_data <- vroom("./test.csv")
test_data
# Libraries
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(poissonreg)
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
## Create a recipe
pen_reg_recipe <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_pen_reg_recipe <- prep(pen_reg_recipe)
bake(prepped_pen_reg_recipe, new_data = log_bikes) # Make sure recipe works on test
bake(prepped_pen_reg_recipe, new_data = test_data) # Make sure recipe works on train
## Penalized regression model
preg_model <- linear_reg(penalty=0.0000000001, mixture=1) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
preg_wf <- workflow() %>%
add_recipe(pen_reg_recipe) %>%
add_model(preg_model) %>%
fit(data=log_bikes)
# Get Predictions for the test set AND format for Kaggle
log_lin_preds <- predict(preg_wf, new_data=test_data) %>% # This predicts log(count)
bind_cols(test_data, .) %>% # Bind test data with predictions
select(datetime, .pred) %>% # Select datetime and predictions
rename(count=.pred) %>% # Rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) # Needed for the right format for Kaggle
# Write predictions to CSV
vroom_write(x=log_lin_preds, file="./LogLinearPreds.csv", delim=",")
# Libraries
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(poissonreg)
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
## Create a recipe
pen_reg_recipe <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_pen_reg_recipe <- prep(pen_reg_recipe)
bake(prepped_pen_reg_recipe, new_data = log_bikes) # Make sure recipe works on test
bake(prepped_pen_reg_recipe, new_data = test_data) # Make sure recipe works on train
## Penalized regression model
preg_model <- linear_reg(penalty=0.0000000001, mixture=1) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
preg_wf <- workflow() %>%
add_recipe(pen_reg_recipe) %>%
add_model(preg_model) %>%
fit(data=log_bikes)
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(preg_wf, new_data = test_data) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
test_data
test_data <- vroom("./test.csv")
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
## Create a recipe
pen_reg_recipe <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_pen_reg_recipe <- prep(pen_reg_recipe)
bake(prepped_pen_reg_recipe, new_data = log_bikes) # Make sure recipe works on test
bake(prepped_pen_reg_recipe, new_data = test_data) # Make sure recipe works on train
## Penalized regression model
preg_model <- linear_reg(penalty=0.0000000001, mixture=1) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
preg_wf <- workflow() %>%
add_recipe(pen_reg_recipe) %>%
add_model(preg_model) %>%
fit(data=log_bikes)
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(preg_wf, new_data = test_data) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
# Write predictions to CSV
vroom_write(x=log_lin_preds, file="./LogLinearPreds.csv", delim=",")
pois_mod <- poisson_reg() %>%
set_engine("glm") # generalized linear model
bike_pois_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(pois_mod) %>%
fit(data = bikes)
# Get Predictions for test set AND format for Kaggle submission
pois_predictions <- predict(bike_pois_workflow, new_data = test_data) %>%
bind_cols(., test_data) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
vroom_write(x = pois_predictions, file="./poisson_predictions.csv", delim=",")
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
## Create a recipe
pen_reg_recipe <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_pen_reg_recipe <- prep(pen_reg_recipe)
## Penalized regression model
preg_model <- linear_reg(penalty=0.0000000001, mixture=1) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
preg_wf <- workflow() %>%
add_recipe(pen_reg_recipe) %>%
add_model(preg_model) %>%
fit(data=log_bikes)
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(preg_wf, new_data = test_data) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
# Write predictions to CSV
vroom_write(x=log_lin_preds, file="./LogLinearPreds.csv", delim=",")
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
## Create a recipe
pen_reg_recipe <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_pen_reg_recipe <- prep(pen_reg_recipe)
## Penalized regression model
preg_model <- linear_reg(penalty=0.00000001, mixture=1) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
preg_wf <- workflow() %>%
add_recipe(pen_reg_recipe) %>%
add_model(preg_model) %>%
fit(data=log_bikes)
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(preg_wf, new_data = test_data) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
# Write predictions to CSV
vroom_write(x=log_lin_preds, file="./LogLinearPreds.csv", delim=",")
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
## Create a recipe
pen_reg_recipe <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_pen_reg_recipe <- prep(pen_reg_recipe)
## Penalized regression model
preg_model <- linear_reg(penalty=0.0001, mixture=1) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
preg_wf <- workflow() %>%
add_recipe(pen_reg_recipe) %>%
add_model(preg_model) %>%
fit(data=log_bikes)
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(preg_wf, new_data = test_data) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
# Write predictions to CSV
vroom_write(x=log_lin_preds, file="./LogLinearPreds.csv", delim=",")
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
## Create a recipe
pen_reg_recipe <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_pen_reg_recipe <- prep(pen_reg_recipe)
## Penalized regression model
preg_model <- linear_reg(penalty=0.001, mixture=1) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
preg_wf <- workflow() %>%
add_recipe(pen_reg_recipe) %>%
add_model(preg_model) %>%
fit(data=log_bikes)
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(preg_wf, new_data = test_data) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
# Write predictions to CSV
vroom_write(x=log_lin_preds, file="./LogLinearPreds.csv", delim=",")
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
## Create a recipe
pen_reg_recipe <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_pen_reg_recipe <- prep(pen_reg_recipe)
## Penalized regression model
preg_model <- linear_reg(penalty=0.0000000001, mixture=1) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
preg_wf <- workflow() %>%
add_recipe(pen_reg_recipe) %>%
add_model(preg_model) %>%
fit(data=log_bikes)
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(preg_wf, new_data = test_data) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
# Write predictions to CSV
vroom_write(x=log_lin_preds, file="./LogLinearPreds.csv", delim=",")
