step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_date(datetime, features="dow") %>%
step_date(datetime, features="month") %>%
step_date(datetime, features="year") %>%
step_rm(datetime) %>%
#step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_recipe <- prep(my_recipe_lin_reg)
bake(prepped_recipe, new_data = log_bikes) #Make sure recipe work on train
bake(prepped_recipe, new_data = test_data) #Make sure recipe works on test
# set up linear regression model
my_mod <- linear_reg() %>%
set_engine("lm")
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = log_bikes)
# Get Predictions for test set AND format for Kaggle submission
predictions <- predict(bike_workflow, new_data = test_data) %>%
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
# Write predictions to CSV file
#vroom_write(x=predictions, file="./test_predictions.csv", delim=",")
vroom_write(x=predictions, file="./justin_test_predictions.csv", delim=",")
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
my_recipe_lin_reg <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_date(datetime, features="dow") %>%
step_date(datetime, features="month") %>%
step_date(datetime, features="year") %>%
step_rm(datetime) %>%
#step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_recipe <- prep(my_recipe_lin_reg)
# set up linear regression model
my_mod <- linear_reg() %>%
set_engine("lm")
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = log_bikes)
# Look at the fitted LM model
extract_fit_engine(bike_workflow) %>%
summary()
# Get Predictions for test set AND format for Kaggle submission
predictions <- predict(bike_workflow, new_data = test_data) %>%
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
# Write predictions to CSV file
#vroom_write(x=predictions, file="./test_predictions.csv", delim=",")
vroom_write(x=predictions, file="./justin_test_predictions.csv", delim=",")
# Libraries
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(poissonreg)
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
# Libraries
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(poissonreg)
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
log_bikes <- bikes %>%
mutate(count=log(count))
my_recipe_lin_reg <- recipe(count~., data=log_bikes) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_date(datetime, features="dow") %>%
step_date(datetime, features="month") %>%
step_date(datetime, features="year") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_recipe <- prep(my_recipe_lin_reg)
bake(prepped_recipe, new_data = log_bikes) #Make sure recipe work on train
bake(prepped_recipe, new_data = test_data) #Make sure recipe works on test
# set up linear regression model
my_mod <- linear_reg() %>%
set_engine("lm")
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = log_bikes)
# Get Predictions for test set AND format for Kaggle submission
predictions <- predict(bike_workflow, new_data = test_data) %>%
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
# Write predictions to CSV file
#vroom_write(x=predictions, file="./test_predictions.csv", delim=",")
vroom_write(x=predictions, file="./justin_test_predictions.csv", delim=",")
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
bikes <- bikes %>%
select(-casual, - registered)
rm(list = ls())
# Libraries
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(poissonreg)
# Read in the Data
bikes <- vroom("./train.csv")
test_data <- vroom("./test.csv")
rm(list = ls())
# Libraries
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(poissonreg)
# Read in the Data
train <- vroom("./train.csv")
test <- vroom("./test.csv")
# Read in the Data
train <- vroom("./train.csv")
test <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
train <- train %>%
select(-casual, - registered)
log_train <- train %>%
mutate(count=log(count))
my_recipe <- recipe(count~., data=log_train) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_date(datetime, features="dow") %>%
step_date(datetime, features="month") %>%
step_date(datetime, features="year") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = test) #Make sure recipe works on test
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = log_train) #Make sure recipe work on train
bake(prepped_recipe, new_data = test) #Make sure recipe works on test
# set up linear regression model
my_mod <- linear_reg() %>%
set_engine("lm")
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = log_train)
# Look at the fitted LM model
extract_fit_engine(bike_workflow) %>%
summary()
# Get Predictions for test set AND format for Kaggle submission
predictions <- predict(bike_workflow, new_data = test) %>%
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
# Get Predictions for test set AND format for Kaggle submission
predictions <- predict(bike_workflow, new_data = test) %>%
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
rm(list = ls())
# Read in the Data
train <- vroom("./train.csv")
test <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
train <- train %>%
select(-casual, - registered)
log_train <- train %>%
mutate(count=log(count))
my_recipe <- recipe(count~., data=log_train) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_date(datetime, features="dow") %>%
step_date(datetime, features="month") %>%
step_date(datetime, features="year") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = log_train) #Make sure recipe work on train
bake(prepped_recipe, new_data = test) #Make sure recipe works on test
# set up linear regression model
my_mod <- linear_reg() %>%
set_engine("lm")
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = log_train)
# Get Predictions for test set AND format for Kaggle submission
predictions <- predict(bike_workflow, new_data = test) %>%
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
test
# Read in the Data
train <- vroom("./train.csv")
rm(list = ls())
# Read in the Data
train <- vroom("./train.csv")
test <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
train <- train %>%
select(-casual, - registered)
log_train <- train %>%
mutate(count=log(count))
my_recipe <- recipe(count~., data=log_train) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_date(datetime, features="dow") %>%
step_date(datetime, features="month") %>%
step_date(datetime, features="year") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = log_train) #Make sure recipe work on train
bake(prepped_recipe, new_data = test) #Make sure recipe works on test
# set up linear regression model
my_mod <- linear_reg() %>%
set_engine("lm")
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = log_train)
# Get Predictions for test set AND format for Kaggle submission
predictions <- predict(bike_workflow, new_data = test) %>%
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
# Write predictions to CSV file
#vroom_write(x=predictions, file="./test_predictions.csv", delim=",")
vroom_write(x=predictions, file="./justin_test_predictions.csv", delim=",") # 1.02303
pois_mod <- poisson_reg() %>%
set_engine("glm") # glm = generalized linear model
pois_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(pois_mod) %>%
fit(data = log_bikes)
pois_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(pois_mod) %>%
fit(data = log_train)
# Read in the Data
train <- vroom("./train.csv")
test <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
train <- train %>%
select(-casual, - registered)
log_train <- train %>%
mutate(count=log(count))
my_recipe <- recipe(count~., data=log_train) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_date(datetime, features="dow") %>%
step_date(datetime, features="month") %>%
step_date(datetime, features="year") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_recipe <- prep(my_recipe)
pois_mod <- poisson_reg() %>%
set_engine("glm") # glm = generalized linear model
pois_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(pois_mod) %>%
fit(data = log_train)
warnings()
# Get Predictions for test set AND format for Kaggle submission
pois_predictions <- predict(pois_workflow, new_data = test) %>%
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
# Get Predictions for test set AND format for Kaggle submission
pois_predictions <- predict(pois_workflow, new_data = test) %>%
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
vroom_write(x = pois_predictions, file="./justin_poisson_predictions.csv", delim=",")
bake(prepped_recipe, new_data = log_train) #Make sure recipe work on train
bake(prepped_recipe, new_data = test) #Make sure recipe works on test
pois_mod <- poisson_reg() %>%
set_engine("glm") # glm = generalized linear model
pois_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(pois_mod) %>%
fit(data = log_train)
# Get Predictions for test set AND format for Kaggle submission
pois_predictions <- predict(pois_workflow, new_data = test) %>%
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
vroom_write(x = pois_predictions, file="./justin_poisson_predictions.csv", delim=",")
log_train <- train %>%
mutate(count=log(count))
penalized_model <- linear_reg(penalty=0.0000000001, mixture=1) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
penalized_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(penalized_model) %>%
fit(data = log_train)
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(preg_wf, new_data = test_data) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
# set workflow
penalized_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(penalized_model) %>%
fit(data = log_train)
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(penalized_wf, new_data = test_data) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
## Get Predictions for test set AND format for Kaggle
penalized_preds <- predict(penalized_wf, new_data = test) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test_data) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
## Get Predictions for test set AND format for Kaggle
penalized_preds <- predict(penalized_wf, new_data = test) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
# Write predictions to CSV
vroom_write(x=penalized_preds, file="./penalized_predictions.csv", delim=",")
# Look at the fitted poisson model
extract_fit_engine(pois_workflow) %>%
summary()
# Look at the fitted penalized model
extract_fit_engine(penalized_wf) %>%
summary()
# Libraries
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(poissonreg)
# Read in the Data
train <- vroom("./train.csv")
test <- vroom("./test.csv")
# Remove casual and registered because we can't use them to predict
train <- train %>%
select(-casual, - registered)
log_train <- train %>%
mutate(count=log(count))
my_recipe <- recipe(count~., data=log_train) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("sunny", "mist", "rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("spring", "summer", "fall", "winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("no", "yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("no", "yes"))) %>%
step_time(datetime, features="hour") %>%
step_date(datetime, features="dow") %>%
step_date(datetime, features="month") %>%
step_date(datetime, features="year") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% # make dummy variables
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = log_train) #Make sure recipe work on train
bake(prepped_recipe, new_data = test) #Make sure recipe works on test
# set up linear regression model
my_mod <- linear_reg() %>%
set_engine("lm")
linear_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = log_train)
# Look at the fitted LM model
extract_fit_engine(linear_workflow) %>%
summary()
# Get Predictions for test set AND format for Kaggle submission
predictions <- predict(linear_workflow, new_data = test) %>%
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test) %>% # Bind predictions with test data
select(datetime, .pred) %>% # only keep datetime and predictions
rename(count=.pred) %>% # rename pred to count (for Kaggle submission)
mutate(count=pmax(0, count)) %>% # round negatives up to zero
mutate(datetime=as.character(format(datetime))) # needed for Kaggle submission
# Write predictions to CSV file
vroom_write(x=predictions, file="./linear_predictions.csv", delim=",")
pois_mod <- poisson_reg() %>%
set_engine("glm") # glm = generalized linear model
pois_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(pois_mod) %>%
fit(data = log_train)
# Look at the fitted poisson model
extract_fit_engine(pois_workflow) %>%
summary()
# Get Predictions for test set AND format for Kaggle submission
pois_predictions <- predict(pois_workflow, new_data = test) %>%
mutate(.pred=exp(.pred)) %>%
bind_cols(., test) %>%
select(datetime, .pred) %>%
rename(count=.pred) %>%
mutate(count=pmax(0, count)) %>%
mutate(datetime=as.character(format(datetime)))
vroom_write(x = pois_predictions, file="./poisson_predictions.csv", delim=",")
penalized_model <- linear_reg(penalty=0.0000000001, mixture=1) %>% # Set model and tuning
set_engine("glmnet")
# set workflow
penalized_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(penalized_model) %>%
fit(data = log_train)
## Get Predictions for test set AND format for Kaggle
penalized_preds <- predict(penalized_wf, new_data = test) %>%
mutate(.pred=exp(.pred)) %>%
bind_cols(., test) %>%
select(datetime, .pred) %>%
rename(count=.pred) %>%
mutate(count=pmax(0, count)) %>%
mutate(datetime=as.character(format(datetime)))
# Write predictions to CSV
vroom_write(x=penalized_preds, file="./penalized_predictions.csv", delim=",")
